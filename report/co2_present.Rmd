---
title: "Global $CO_{2}$ Emissions in 1997"
short: "What Keeling missed all these years"
journal: "AER" # AER, AEJ, PP, JEL
month: "`r format(Sys.Date(), '%m')`"
year: "`r format(Sys.Date(), '%Y')`"
vol: 0
issue: 0
keywords:
  - Replication
  - Modern Science
author:
  - name: Majid Maki-Nayeri
    firstname: Maki-Nayeri
    surname: Maki-Nayeri
    email: m_maki@ischool.berkeley.edu
    affiliation: UC Berkeley, School of Information
  - name: Vinod Bakthavachalam
    firstname: Vinod
    surname: Bakthavachalam
    email: vinodb@ischool.berkeley.edu
    affiliation: UC Berkeley, School of Information
  - name: Artem Lebedev
    firstname: Artem 
    surname: Lebedev
    email: artem.lebedev@berkeley.edu
    affiliation: McMaster University, Department of Chemistry and Biochemistry
acknowledgements: | 
  The authors would like to thank their instructors from MIDS 271.
abstract: | 
  One of the very interesting features of Keeling and colleagues’ research is that they were able to evaluate, and re-evaluate the data as new series of measurements were released. This permitted the evaluation of previous models’ performance and a much more difficult question: If their models’ predictions were “off” was this the result of a failure of the model, or a change in the system?
header-includes: 
  - '\usepackage{graphicx}'
  - '\usepackage{booktabs}'
output: rticles::aea_article
---

```{r setup, echo=FALSE}
## default to not show code, unless we ask for it.
knitr::opts_chunk$set(echo=FALSE, warning = FALSE, dpi=1000)
options(digits = 3)
```


```{r load packages, echo = FALSE, message = FALSE}
library(tidyverse)
library(tsibble)
library(latex2exp)
theme_set(theme_minimal())
```

# Introduction

\textcolor{red}{In this introduction, you can assume that your reader will have just read your 1997 report. In this introduc-
tion, very briefly pose the question that you are evaluating, and describe what (if anything) has changed in
the data generating process between 1997 and the present.} 

# Mona Loa $CO_{2}$ Data 
The most current data is provided by the United States' National Oceanic and Atmospheric Administration, on a data page [[here](https://gml.noaa.gov/ccgg/trends/data.html)]. Gather the most recent weekly data from this page. (A group that is interested in even more data management might choose to work with the [hourly data](https://gml.noaa.gov/aftp/data/trace_gases/co2/in-situ/surface/mlo/co2_mlo_surface-insitu_1_ccgg_HourlyData.txt).) 

Create a data pipeline that starts by reading from the appropriate URL, and ends by saving an object called `co2_present` that is a suitable time series object. 

## Recent Trends in Atmospheric Carbon 
Conduct the same EDA on this data. Describe how the Keeling Curve evolved from 1997 to the present, noting where the series seems to be following similar trends to the series that you "evaluated in 1997" and where the series seems to be following different trends. This EDA can use the same, or very similar tools and views as you provided in your 1997 report. 

\textcolor{red}{Atmospheric carbon is plotted in \autoref{fig:carbon}, and shows some worrying trends. Just look at how wobbly that line is. How is it possible that we are not living in a simulation, when the lines that plots monthly average $CO_{2}$ looks like this?}

```{r plot the keeling curve, echo = FALSE}
fig_1 <- tsibble::as_tsibble(co2) %>%
  ggplot() + 
  aes(x=index, y=value) + 
  geom_line(color = 'steelblue') +
  labs(
    title = TeX(r'(Monthly Mean $CO_2$)'),
    subtitle = 'The "Keeling Curve"',
    x = 'Month and Year',
    y = TeX(r'($CO_2$ parts per million)')
  )

ggsave(filename = './figures/plot_1.pdf', plot = fig_1, device = "pdf", units = c("in"), height=5, width=10)
```

\begin{figure}
  \includegraphics[width=.8\linewidth]{./figures/plot_1.pdf}
  \caption{An uncareful plot.\label{fig:carbon}}
  \begin{figurenotes}
    After giving a declarative statement about what is in the plot, it is useful to provide a very concise interpretation of what you see, or how you read the plot. It should be possible for a reader to \textit{almost} read your entire report from tables, figures, and estimated models.
  \end{figurenotes}
\end{figure} 

\textcolor{red}{Even more, a careful examination of \autoref{tab:table_1} suggests some worrying trends in headings and columns. }

\begin{table}
  \caption{What is happening with headers?\label{tab:table_1}}
  \begin{tabular}{lll}
    \toprule 
    & Heading 1 & Heading 2 \\
    Row 1 & 1 & 2 \\
    Row 2 & 3 & 4 \\
    \bottomrule
  \end{tabular}
  \begin{tablenotes}
    Table notes environment without optional leadin.
  \end{tablenotes}
\end{table}

# Models and Forecasts 
\textcolor{red}{While these plots might be compelling, it is often challenging to learn the exact nature of a time serires process from only these overview, "time vs. outcome" style of plots. In this section, we present evaluate two classes models to assess which time series model is most appropriate to use. }

## Linear Models 

\textcolor{red}{Descriptively compare realized atmospheric CO2 levels to those predicted by your forecast from a linear time model in 1997 (i.e. "Task 2a"). (You do not need to run any formal tests for this task.) }

\begin{equation}
\label{eq:one}
\text{CO}_{2} = \phi_{0} + \phi_{1} + \epsilon_{eit}
\end{equation} 


We estimate best fitting parameters on this model in the following way, 
```{r make fake data}
## We wouldn't show this in a report.
d <- data.frame(
  y=1:10 + rnorm(n=10), 
  x=2:11
)
## But we would show the next chunk. 
```

```{r estimate a model, echo=TRUE}
model_1 <- lm(y ~ x, data = d)
```

## ARIMA Models 

\textcolor{red}{Descriptively compare realized atmospheric CO2 levels to those predicted by your forecast from the ARIMA model that you fitted in 1997 (i.e. "Task 3a"). Describe how the Keeling Curve evolved from 1997 to the present.}

## Performance of 1997 linear and ARIMA models 

\textcolor{red}{In 1997 you made predictions about the first time that CO2 would cross 420 ppm. How close were your models to the truth?}

\textcolor{red}{After reflecting on your performance on this threshold-prediction task, continue to use the weekly data to generate a month-average series from 1997 to the present, and compare the overall forecasting performance of your models from Parts 2a and 3b over the entire period. (You should conduct formal tests for this task.)}

## Best models on present data

\textcolor{red}{Seasonally adjust the weekly NOAA data, and split both seasonally-adjusted (SA) and non-seasonally-adjusted (NSA) series into training and test sets, using the last two years of observations as the test sets. For both SA and NSA series, fit ARIMA models using all appropriate steps. Measure and discuss how your models perform in-sample and (psuedo-) out-of-sample, comparing candidate models and explaining your choice. In addition, fit a polynomial time-trend model to the seasonally-adjusted series and compare its performance to that of your ARIMA model.}

## Forecasts: How bad could it get?

\textcolor{red}{With the non-seasonally adjusted data series, generate predictions for when atmospheric CO2 is expected to be at 420 ppm and 500 ppm levels for the first and final times (consider prediction intervals as well as point estimates in your answer). Generate a prediction for atmospheric CO2 levels in the year 2122. How confident are you that these will be accurate predictions?}

```{r}
prediction_1 <- predict(
  object = model_1, 
  newdata = data.frame(x=11), 
  interval = 'prediction'
)
```


\textcolor{red}{Because we have fitted a model, we can make predictions from that model. Our preferred model, named in \autoref{eq:one} is quite simple, and as you might notice, does not in fact match up with the model that we have fitted. However, from this model is is possible to reason about what the outcomes would be if the *input concept* were to be slightly ouside of the observed data range. In particular, if *input concept* were as high as $11$, then we would expect the *output concept* to be `r prediction_1[1,1]`, with a prediction interval that ranges from [`r prediction_1[1,2]`, `r prediction_1[1,3]`]}}

# Conclusions 

\textcolor{red}{What to conclude is unclear. }

\bibliographystyle{aea}
\bibliography{references}

\appendix
\section{Appendix: Model Robustness}

\textcolor{red}{While the most plausible model that we estimate is reported in the main, "Modeling" section, in this appendix to the article we examine alternative models. Here, our intent is to provide a skeptic that does not accept our assessment of this model as an ARIMA of order (1,2,3) an understanding of model forecasts under alternative scenarios. }
